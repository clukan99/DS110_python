{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing PyTorch libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompID</th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CompID     TV  radio  newspaper  sales\n",
       "0       1  230.1   37.8       69.2   22.1\n",
       "1       2   44.5   39.3       45.1   10.4\n",
       "2       3   17.2   45.9       69.3    9.3\n",
       "3       4  151.5   41.3       58.5   18.5\n",
       "4       5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_data = pd.read_csv(\"../../DATA/Advertising.csv\")\n",
    "ad_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Creating a network model\n",
    "This will be a linear model with an input of 1 and ann output of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(Net, self).__init__()\n",
    "       self.layer = torch.nn.Linear(1, 1)\n",
    "\n",
    "   def forward(self, x):\n",
    "       x = self.layer(x)      \n",
    "       return x\n",
    "\n",
    "LinearRegressionModel = Net()\n",
    "print(LinearRegressionModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets let x = radio and y = sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =np.asarray(ad_data['radio'])\n",
    "y = np.asarray(ad_data['sales'])\n",
    "#plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the numpy array to a tensor the shape of the input size. In this case (-1,1)???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_train = torch.from_numpy(x.reshape(-1,1)).float()\n",
    "sales_train = torch.from_numpy(y.reshape(-1,1)).float()\n",
    "#print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Optimizer and Loss\n",
    "Note that lr = learning rate\n",
    "criterion is loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(LinearRegressionModel.parameters(), lr=0.2)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training\n",
    "We are choosing epochs of 250 to iterate and find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 56.477542877197266\n",
      "epoch 2, loss 1539532.75\n",
      "epoch 3, loss 141807042560.0\n",
      "epoch 4, loss 1.3062217465331712e+16\n",
      "epoch 5, loss 1.2031932169223468e+21\n",
      "epoch 6, loss 1.1082924665658381e+26\n",
      "epoch 7, loss 1.0208768039106638e+31\n",
      "epoch 8, loss 9.403554956144903e+35\n",
      "epoch 9, loss inf\n",
      "epoch 10, loss inf\n",
      "epoch 11, loss inf\n",
      "epoch 12, loss inf\n",
      "epoch 13, loss inf\n",
      "epoch 14, loss inf\n",
      "epoch 15, loss inf\n",
      "epoch 16, loss inf\n",
      "epoch 17, loss nan\n",
      "epoch 18, loss nan\n",
      "epoch 19, loss nan\n",
      "epoch 20, loss nan\n",
      "epoch 21, loss nan\n",
      "epoch 22, loss nan\n",
      "epoch 23, loss nan\n",
      "epoch 24, loss nan\n",
      "epoch 25, loss nan\n",
      "epoch 26, loss nan\n",
      "epoch 27, loss nan\n",
      "epoch 28, loss nan\n",
      "epoch 29, loss nan\n",
      "epoch 30, loss nan\n",
      "epoch 31, loss nan\n",
      "epoch 32, loss nan\n",
      "epoch 33, loss nan\n",
      "epoch 34, loss nan\n",
      "epoch 35, loss nan\n",
      "epoch 36, loss nan\n",
      "epoch 37, loss nan\n",
      "epoch 38, loss nan\n",
      "epoch 39, loss nan\n",
      "epoch 40, loss nan\n",
      "epoch 41, loss nan\n",
      "epoch 42, loss nan\n",
      "epoch 43, loss nan\n",
      "epoch 44, loss nan\n",
      "epoch 45, loss nan\n",
      "epoch 46, loss nan\n",
      "epoch 47, loss nan\n",
      "epoch 48, loss nan\n",
      "epoch 49, loss nan\n",
      "epoch 50, loss nan\n",
      "epoch 51, loss nan\n",
      "epoch 52, loss nan\n",
      "epoch 53, loss nan\n",
      "epoch 54, loss nan\n",
      "epoch 55, loss nan\n",
      "epoch 56, loss nan\n",
      "epoch 57, loss nan\n",
      "epoch 58, loss nan\n",
      "epoch 59, loss nan\n",
      "epoch 60, loss nan\n",
      "epoch 61, loss nan\n",
      "epoch 62, loss nan\n",
      "epoch 63, loss nan\n",
      "epoch 64, loss nan\n",
      "epoch 65, loss nan\n",
      "epoch 66, loss nan\n",
      "epoch 67, loss nan\n",
      "epoch 68, loss nan\n",
      "epoch 69, loss nan\n",
      "epoch 70, loss nan\n",
      "epoch 71, loss nan\n",
      "epoch 72, loss nan\n",
      "epoch 73, loss nan\n",
      "epoch 74, loss nan\n",
      "epoch 75, loss nan\n",
      "epoch 76, loss nan\n",
      "epoch 77, loss nan\n",
      "epoch 78, loss nan\n",
      "epoch 79, loss nan\n",
      "epoch 80, loss nan\n",
      "epoch 81, loss nan\n",
      "epoch 82, loss nan\n",
      "epoch 83, loss nan\n",
      "epoch 84, loss nan\n",
      "epoch 85, loss nan\n",
      "epoch 86, loss nan\n",
      "epoch 87, loss nan\n",
      "epoch 88, loss nan\n",
      "epoch 89, loss nan\n",
      "epoch 90, loss nan\n",
      "epoch 91, loss nan\n",
      "epoch 92, loss nan\n",
      "epoch 93, loss nan\n",
      "epoch 94, loss nan\n",
      "epoch 95, loss nan\n",
      "epoch 96, loss nan\n",
      "epoch 97, loss nan\n",
      "epoch 98, loss nan\n",
      "epoch 99, loss nan\n",
      "epoch 100, loss nan\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = torch.from_numpy(np.asarray(radio_train)).requires_grad_()\n",
    "    labels = torch.from_numpy(np.asarray(sales_train))\n",
    "\n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    # Forward to get output\n",
    "    outputs = LinearRegressionModel(inputs)\n",
    "\n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = LinearRegressionModel(torch.from_numpy(np.asarray(radio_train)).requires_grad_()).data.numpy()\n",
    "predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3edbd7b23b0fac25ed01096b34e5f59511cb659c0b1d4bb21fa4d1eb2f403c11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
